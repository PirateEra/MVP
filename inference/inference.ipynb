{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import jsonlines\n",
    "import json\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from FiDT5 import FiDT5\n",
    "\n",
    "import random\n",
    "from beir_eval import run_direct_rerank_eval\n",
    "from beir_length_mapping import BEIR_LENGTH_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    data = []\n",
    "    with jsonlines.open(path, 'r') as reader:\n",
    "        for instance in reader:\n",
    "            data.append(instance)\n",
    "    return data\n",
    "\n",
    "class ListT5Evaluator():\n",
    "    def __init__(self, args):\n",
    "        self.idx = 0\n",
    "        self.imsi = []\n",
    "        self.args = args\n",
    "        self.tok = T5Tokenizer.from_pretrained(self.args.model_path)\n",
    "\n",
    "        # For Evaluate all datasets (Using Folder as input_path)\n",
    "        if not os.path.isdir(self.args.input_path):\n",
    "            self.test_file = read_jsonl(self.args.input_path)\n",
    "            print(f\"Input path: {self.args.input_path}\")\n",
    "        self.idx2tokid = self.tok.encode(' '.join([str(x) for x in range(1, self.args.listwise_k+1)]))[:-1]\n",
    "        self.model = self.load_model()\n",
    "        self.num_forward = 0\n",
    "\n",
    "    def write_json_file(self, path, data):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        print(f\"Writing to {path} done!\")\n",
    "\n",
    "    def write_jsonl_file(self, path, data):\n",
    "        if self.args.measure_flops:\n",
    "            self.prof.stop_profile()\n",
    "            self.flops = self.prof.get_total_flops()\n",
    "        else:\n",
    "            self.flops = 0\n",
    "        # print(f\"Flops: {self.flops}!\")\n",
    "        with jsonlines.open(path, 'w') as writer:\n",
    "            writer.write_all(data)\n",
    "        # print(f\"Writing to {path} done!\")\n",
    "\n",
    "    def load_model(self):\n",
    "        start = time.time()\n",
    "        print(\"Loading model..\")\n",
    "        print(f\"Loading fid model from {self.args.model_path}\")\n",
    "        print(f\"Pooling type: {self.args.pooling_type}\")\n",
    "        model = FiDT5.from_pretrained(self.args.model_path,n_passages = self.args.topk, pooling_type=self.args.pooling_type,\n",
    "                                       n_special_tokens=self.args.n_special_tokens, tokenizer=self.tok).to('cuda')\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Done! took {end-start} second\")\n",
    "        model.eval()\n",
    "        if self.args.measure_flops:\n",
    "            self.prof = FlopsProfiler(model)\n",
    "            self.prof.start_profile()\n",
    "        return model\n",
    "\n",
    "    def make_input_tensors(self, texts):\n",
    "        raw = self.tok(texts, return_tensors='pt',\n",
    "                padding=self.args.padding, max_length=self.args.max_input_length,\n",
    "                truncation=True).to('cuda')\n",
    "        input_tensors = {'input_ids': raw['input_ids'].unsqueeze(0),\n",
    "                'attention_mask': raw['attention_mask'].unsqueeze(0)}\n",
    "        return input_tensors\n",
    "    \n",
    "    def make_listwise_text(self, question, ctxs, sep='|'):\n",
    "        out = []\n",
    "        if self.args.pooling_type == 'rv':\n",
    "            for i in range(len(ctxs)):\n",
    "                if self.args.n_special_tokens > 1:\n",
    "                    special_str = \"\".join([f\"<Relevance_{x}>\" for x in range(1, 1+self.args.n_special_tokens)])\n",
    "                    text = f\"{special_str} | Query: {question} | Context: {ctxs[i]}\"                    \n",
    "                else:\n",
    "                    text = f\"<Relevance> | Query: {question} | Context: {ctxs[i]}\"\n",
    "                out.append(text)\n",
    "        else:\n",
    "            for i in range(len(ctxs)):\n",
    "                if self.args.n_special_tokens > 1:\n",
    "                    special_str = \"\".join([f\"<extra_id_{x}>\" for x in range(0, self.args.n_special_tokens)])\n",
    "                    text = f\"{special_str} | Query: {question} | Context: {ctxs[i]}\"\n",
    "                # text = f\"<extra_id_17>, Query: {question}, Context: {ctxs[i]}\"\n",
    "                \n",
    "                out.append(text)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def run_inference(self, input_tensors):\n",
    "        output = self.model.generate_by_single_logit(**input_tensors,\n",
    "                                                     max_length = self.args.max_gen_length,\n",
    "                                                     return_dict=False),\n",
    "        self.num_forward += 1\n",
    "        \n",
    "        return output[0]\n",
    " \n",
    "    def get_rel_index(self, output, mode='default', k=-1):\n",
    "        if k == -1:\n",
    "            k = self.args.out_k\n",
    "        \n",
    "        gen_out = None\n",
    "        topk_possible = [str(x) for x in range(1, k+1)]\n",
    "        \n",
    "        if mode=='default':\n",
    "            gen_out = self.tok.batch_decode(output.sequences, skip_special_tokens=True)\n",
    "            gen_out = gen_out[0].split(' ')\n",
    "        elif mode=='logit':\n",
    "            topk_logits = output.scores[0].topk(k + 10).indices\n",
    "            gen_out = [x.split() for x in self.tok.batch_decode(topk_logits, skip_special_tokens=True)][0]\n",
    "        \n",
    "        print(\"Model output: \", gen_out)        \n",
    "        out_rel_indexes = []\n",
    "        for i, x in enumerate(gen_out):\n",
    "            if x in topk_possible:\n",
    "                out_rel_indexes.append(x)\n",
    "                topk_possible.remove(x)\n",
    "        \n",
    "        if len(out_rel_indexes) < k:\n",
    "            if 'rev' in self.args.model_path:\n",
    "                out_rel_indexes = out_rel_indexes + topk_possible\n",
    "            else:    \n",
    "                out_rel_indexes = topk_possible[::-1] + out_rel_indexes\n",
    "\n",
    "        return out_rel_indexes\n",
    "\n",
    "    def direct_rerank(self, question, ctxs, k=-1):\n",
    "        full_input_texts = self.make_listwise_text(question, ctxs)\n",
    "        try:\n",
    "            input_tensors = self.make_input_tensors(full_input_texts)\n",
    "        except:\n",
    "            import IPython;\n",
    "            IPython.embed()\n",
    "            exit()\n",
    "        output = self.run_inference(input_tensors)\n",
    "\n",
    "        out_k_rel_index = [str(x+1) for x in output[0]]\n",
    "\n",
    "        return out_k_rel_index\n",
    "    \n",
    "    def run_direct_rerank(self):\n",
    "        reranked_instances = []\n",
    "        len_question = []\n",
    "        for instance in tqdm(self.test_file):\n",
    "\n",
    "            question = instance[self.args.question_text_key]\n",
    "            items = instance[self.args.firststage_result_key][:self.args.topk]\n",
    "\n",
    "            if self.args.initial == 'origin':\n",
    "                pass\n",
    "            elif self.args.initial == 'reverse':\n",
    "                items = items[::-1]\n",
    "            elif self.args.initial == 'random':\n",
    "                random.shuffle(items)\n",
    "            topk_ctxs = [x[self.args.text_key] for x in items]\n",
    "            self.model.n_passages = len(topk_ctxs)\n",
    "            # self.model.encoder.encoder_batch_size = self.args.encoder_batch_size\n",
    "            len_question.append(len(question))\n",
    "\n",
    "            if len(topk_ctxs) > 0:\n",
    "                index = self.direct_rerank(question, topk_ctxs, k=self.args.topk)\n",
    "            else:\n",
    "                # If no candidate passages are available, skip the instance\n",
    "                index = []\n",
    "            reranked_items = []\n",
    "\n",
    "            for i, pid in enumerate(index):\n",
    "                pid = int(pid) - 1\n",
    "                template  = items[pid]\n",
    "                template['orig_'+self.args.score_key] = template[self.args.score_key]\n",
    "                template[self.args.score_key] = 100000 - i                \n",
    "\n",
    "                reranked_items.append(template)\n",
    "            instance[self.args.firststage_result_key] = reranked_items\n",
    "\n",
    "            reranked_instances.append(instance)\n",
    "\n",
    "        self.write_jsonl_file(self.args.output_path, reranked_instances)\n",
    "        ndcg_k, scores = run_direct_rerank_eval(self.args.output_path, k=self.args.topk)\n",
    "\n",
    "        if self.args.store_result:\n",
    "            data_name = self.args.input_path.split('/')[-1].split('.')[0]\n",
    "            result_file = f\"./result_{data_name}.txt\"\n",
    "            log_str = \"\"\n",
    "            log_str += f\"MODEL : {self.args.model_path}\\n\"\n",
    "            log_str += f\"n_special_tokens : {self.args.n_special_tokens}\\n\"\n",
    "            log_str += f\"Token loc : {self.args.special_loc}\\n\"\n",
    "            log_str += f\"ndcg@10 : {ndcg_k}\\n\"\n",
    "            log_str += \"==================================================\\n\"\n",
    "            with open(result_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(log_str)\n",
    "        return ndcg_k, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reranker(args):\n",
    "    module = ListT5Evaluator(args)\n",
    "\n",
    "    he = time.time()\n",
    "    ndcg_10, scores = module.run_direct_rerank()\n",
    "    hehe = time.time()\n",
    "    print(f\"Total elapsed time: {hehe-he}\")    \n",
    "    print(\"Elasped time per query: \", (hehe-he)/len(module.test_file))\n",
    "    if args.measure_flops:\n",
    "        flops = module.flops\n",
    "        num_forward = module.num_forward\n",
    "    else:\n",
    "        flops = 0\n",
    "        num_forward = 0\n",
    "\n",
    "    return ndcg_10, scores, flops, num_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arg(args=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Dataset key setup\n",
    "    parser.add_argument('--firststage_result_key', default='bm25_results', type=str)\n",
    "    parser.add_argument('--docid_key', default='docid', type=str)\n",
    "    parser.add_argument('--pid_key', default='pid', type=str)\n",
    "    parser.add_argument('--qrels_key', default='qrels', type=str)\n",
    "    parser.add_argument('--score_key', default='bm25_score', type=str)\n",
    "    parser.add_argument('--question_text_key', default='q_text', type=str)\n",
    "    parser.add_argument('--text_key', default='text', type=str)\n",
    "    parser.add_argument('--title_key', default='title', type=str)\n",
    "    parser.add_argument('--pooling_type', default=None, type=str)\n",
    "    parser.add_argument('--n_special_tokens', default=1, type=int)\n",
    "    parser.add_argument('--store_result', default=False, type=bool)\n",
    "    parser.add_argument('--softmax_temp', default=1.0, type=float)\n",
    "    parser.add_argument('--device', default='cuda:4', type=str) # cuda0, cuda1, cpu\n",
    "    parser.add_argument('--model_path', default='Soyoung97/ListT5-base', type=str)\n",
    "    parser.add_argument('--topk', default=100, type=int, help='number of initial candidate passages to consider') \n",
    "    parser.add_argument('--score_mode', default='default', type=str, help='default or logit')\n",
    "    \n",
    "    parser.add_argument('--max_input_length', type=int, default=-1) # depends on each individual data setup\n",
    "    parser.add_argument('--padding', default='max_length', type=str)\n",
    "    parser.add_argument('--listwise_k', default=5, type=int)\n",
    "    parser.add_argument('--rerank_topk', default=10, type=int)\n",
    "    parser.add_argument('--decoding_strategy', default='single', type=str)\n",
    "    parser.add_argument('--target_seq', default='token', type=str)\n",
    "\n",
    "    parser.add_argument('--encoder-batch-size', default=100, type=int) # Because of the memory issue, we need to Devide the input into small batch size. (max_input_length -> encoder-batch-size. 256 -> 100, 512 -> 50. 1024 -> 25 in 24GB gpu)\n",
    "\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--input_path', type=str, default='./trec-covid.jsonl')\n",
    "    parser.add_argument('--output_path', type=str, default='./outputs/trec-covid.jsonl')\n",
    "    parser.add_argument('--special_loc', default=0, type=int)\n",
    "    # Testing positional Bias\n",
    "    parser.add_argument('--initial', default='origin', type=str)\n",
    "\n",
    "    # profiling setup\n",
    "    parser.add_argument('--measure_flops', action='store_true')\n",
    "    parser.add_argument('--skip_no_candidate', action='store_true', help='skip instances with no gold qrels included at first-stage retrieval for faster inference, only works when gold qrels are available')\n",
    "    parser.add_argument('--skip_issubset', action='store_true', help='skip the rest of reranking when the gold qrels is a subset of reranked output for faster inference, only works when gold qrels are available')\n",
    "    \n",
    "    return parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(firststage_result_key='bm25_results', docid_key='docid', pid_key='pid', qrels_key='qrels', score_key='bm25_score', question_text_key='q_text', text_key='text', title_key='title', pooling_type='extra', n_special_tokens=4, store_result=False, softmax_temp=1.0, device='cuda:4', model_path='/data/kjun/checkpoints/MVT5_v2_first/MVT5_s_11_special_4_seed_0_first_0_base_extra/tfmr_7_step2496', topk=100, score_mode='default', max_input_length=-1, padding='max_length', listwise_k=5, rerank_topk=10, decoding_strategy='single', target_seq='token', encoder_batch_size=100, seed=0, input_path='./eval_data/baseline/dl19.jsonl', output_path='./outputs/listt5-dl19_default.jsonl', special_loc=0, initial='origin', measure_flops=False, skip_no_candidate=False, skip_issubset=False, max_gen_length=101)\n"
     ]
    }
   ],
   "source": [
    "arguments = ['--input_path', './eval_data/baseline/dl19.jsonl',\n",
    "             '--output_path', './outputs/listt5-dl19_default.jsonl',\n",
    "             '--topk', '100',\n",
    "             '--pooling_type', 'extra',\n",
    "             '--n_special_tokens', '4',\n",
    "             '--model_path', '/data/kjun/checkpoints/MVT5_v2_first/MVT5_s_11_special_4_seed_0_first_0_base_extra/tfmr_7_step2496']\n",
    "args = parse_arg(arguments)\n",
    "args.max_gen_length = args.topk + 1\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path: ./eval_data/baseline/dl19.jsonl\n",
      "Loading model..\n",
      "Loading fid model from /data/kjun/checkpoints/MVT5_v2_first/MVT5_s_11_special_4_seed_0_first_0_base_extra/tfmr_7_step2496\n",
      "Pooling type: extra\n",
      "Done! took 2.3137171268463135 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path: ./eval_data/baseline/dl20.jsonl\n",
      "Loading model..\n",
      "Loading fid model from /data/kjun/checkpoints/MVT5_v2_first/MVT5_s_11_special_4_seed_0_first_0_base_extra/tfmr_7_step2496\n",
      "Pooling type: extra\n",
      "Done! took 2.2600021362304688 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "ndcgs_per_view_all_dl19 = []\n",
    "reranked_instances_per_view_all_dl19 = []\n",
    "\n",
    "ndcgs_per_view_all_dl20 = []\n",
    "reranked_instances_per_view_all_dl20 = []\n",
    "\n",
    "data_path = ['./eval_data/baseline/dl19.jsonl',\n",
    "             './eval_data/baseline/dl20.jsonl']\n",
    "\n",
    "# model_path = ['/home/tako/kjun/checkpoints/listt5/test/ortho_weight/10',\n",
    "#               '/home/tako/kjun/checkpoints/listt5/test/ortho_weight/100',\n",
    "#               '/home/tako/kjun/checkpoints/listt5/test/ortho_weight/1000',\n",
    "#               '/home/tako/kjun/checkpoints/listt5/test/ortho_weight/10000']\n",
    "model_path = ['/data/kjun/checkpoints/MVT5_v2_first/MVT5_s_11_special_4_seed_0_first_0_base_extra/tfmr_7_step2496']\n",
    "\n",
    "for path in data_path:\n",
    "    for model_p in model_path:\n",
    "        args.input_path = path\n",
    "        args.model_path = model_p\n",
    "        ndcgs_per_view = []\n",
    "        reranked_instances_per_view = []\n",
    "\n",
    "        module = ListT5Evaluator(args)\n",
    "        for name in BEIR_LENGTH_MAPPING:\n",
    "            if name in module.args.input_path:\n",
    "                module.args.max_input_length = BEIR_LENGTH_MAPPING[name]\n",
    "\n",
    "        torch.cuda.empty_cache()    \n",
    "        \n",
    "        reranked_instances = []\n",
    "        len_question = []\n",
    "        ndcg_query = []\n",
    "        for instance in tqdm(module.test_file):\n",
    "            question = instance[module.args.question_text_key]\n",
    "            items = instance[module.args.firststage_result_key][:module.args.topk]\n",
    "            topk_ctxs = [x[module.args.text_key] for x in items]\n",
    "            qrels = instance[module.args.qrels_key]\n",
    "            \n",
    "            module.model.n_passages = len(topk_ctxs)\n",
    "            module.model.encoder.encoder_batch_size = module.args.encoder_batch_size\n",
    "            len_question.append(len(question))\n",
    "            \n",
    "            full_input_texts = module.make_listwise_text(question, topk_ctxs)\n",
    "            input_tensors = module.make_input_tensors(full_input_texts)\n",
    "            \n",
    "            output = module.run_inference(input_tensors)\n",
    "            out_k_rel_index = [str(x+1) for x in output[0]]\n",
    "            break\n",
    "            reranked_items = []\n",
    "            \n",
    "            for i, pid in enumerate(out_k_rel_index):\n",
    "                pid = int(pid) - 1\n",
    "                template  = items[pid]\n",
    "                template['orig_'+module.args.score_key] = template[module.args.score_key]\n",
    "                template[module.args.score_key] = 100000 - i                \n",
    "\n",
    "                reranked_items.append(template)\n",
    "            instance[module.args.firststage_result_key] = reranked_items\n",
    "\n",
    "            reranked_instances.append(instance)\n",
    "            \n",
    "            postfix = f\"query{i+1}\"\n",
    "            output_path = module.args.output_path.replace('.jsonl', f'_{postfix}.jsonl')\n",
    "            module.write_jsonl_file(output_path, [instance])\n",
    "            ndcg_k, scores = run_direct_rerank_eval(\n",
    "                # module.args.model_path,\n",
    "                # module.args.input_path,\n",
    "                data_path=output_path,\n",
    "                k=module.args.topk\n",
    "            )\n",
    "            ndcg_query.append(ndcg_k)\n",
    "        ndcgs_per_view.append(ndcg_query)\n",
    "        reranked_instances_per_view.append(reranked_instances)\n",
    "        \n",
    "    if 'dl19' in path:\n",
    "        ndcgs_per_view_all_dl19.append(ndcgs_per_view)\n",
    "        reranked_instances_per_view_all_dl19.append(reranked_instances_per_view)\n",
    "    elif 'dl20' in path:\n",
    "        ndcgs_per_view_all_dl20.append(ndcgs_per_view)\n",
    "        reranked_instances_per_view_all_dl20.append(reranked_instances_per_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndcgs_per_view_all_dl19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_reranked_instances_per_view_all_dl19 = reranked_instances_per_view_all_dl19\n",
    "backup_reranked_instances_per_view_all_dl20 = reranked_instances_per_view_all_dl20\n",
    "backup_ndcgs_per_view_all_dl19 = ndcgs_per_view_all_dl19\n",
    "backup_ndcgs_per_view_all_dl20 = ndcgs_per_view_all_dl20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndcgs_per_view to df\n",
    "# list to ndarray\n",
    "ndcgs_df_dl19 = []\n",
    "for i in range(len(ndcgs_per_view_all_dl19)):\n",
    "    ndcgs_per_view = np.array(ndcgs_per_view_all_dl19[i])\n",
    "    ndcgs_df = pd.DataFrame(ndcgs_per_view.transpose(), columns=['view0', 'view1', 'view2', 'view3'])\n",
    "    ndcgs_df\n",
    "    # row 별 평균과 표준편차 계산\n",
    "    ndcgs_df['mean'] = ndcgs_df.mean(axis=1)\n",
    "    ndcgs_df['std'] = ndcgs_df.std(axis=1)\n",
    "    ndcgs_df_dl19.append(ndcgs_df)\n",
    "\n",
    "ndcgs_df_dl20 = []\n",
    "\n",
    "for i in range(len(ndcgs_per_view_all_dl20)):\n",
    "    ndcgs_per_view = np.array(ndcgs_per_view_all_dl20[i])\n",
    "    ndcgs_df = pd.DataFrame(ndcgs_per_view.transpose(), columns=['view0', 'view1', 'view2', 'view3'])\n",
    "    ndcgs_df\n",
    "    # row 별 평균과 표준편차 계산\n",
    "    ndcgs_df['mean'] = ndcgs_df.mean(axis=1)\n",
    "    ndcgs_df['std'] = ndcgs_df.std(axis=1)\n",
    "    ndcgs_df_dl20.append(ndcgs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORACLE Weight 10 NDCG@10: 0.7536, 0.72\n",
      "ORACLE Weight 100 NDCG@10: 0.7528, 0.7286\n",
      "ORACLE Weight 1000 NDCG@10: 0.7539, 0.7298\n",
      "ORACLE Weight 10000 NDCG@10: 0.7552, 0.7303\n"
     ]
    }
   ],
   "source": [
    "start = 10\n",
    "for i in range(len(ndcgs_df_dl19)):\n",
    "    ndcgs_df_19_max = ndcgs_df_dl19[i].assign(max=ndcgs_df_dl19[i].iloc[:,:4].max(axis=1))\n",
    "    ndcgs_df_20_max = ndcgs_df_dl20[i].assign(max=ndcgs_df_dl20[i].iloc[:,:4].max(axis=1))\n",
    "\n",
    "    ndcgs_df_19_max_mean = ndcgs_df_19_max['max'].mean().round(4)\n",
    "    ndcgs_df_20_max_mean = ndcgs_df_20_max['max'].mean().round(4)\n",
    "\n",
    "    print(f'ORACLE Weight {start} NDCG@10: {ndcgs_df_19_max_mean}, {ndcgs_df_20_max_mean}')\n",
    "\n",
    "    start = start * 10\n",
    "    # ndcgs_df.to_csv(f'./outputs/ndcgs_dl19_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302842592592592"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 row에서 max인 cell 의 value 추출\n",
    "ndcgs_df_max = ndcgs_df_dl20[3].assign(max=ndcgs_df.iloc[:, :4].max(axis=1))\n",
    "ndcgs_df_max['max'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view0</th>\n",
       "      <th>view1</th>\n",
       "      <th>view2</th>\n",
       "      <th>view3</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.75451</td>\n",
       "      <td>0.86365</td>\n",
       "      <td>0.68322</td>\n",
       "      <td>0.74486</td>\n",
       "      <td>0.761560</td>\n",
       "      <td>6.497714e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.67139</td>\n",
       "      <td>0.70392</td>\n",
       "      <td>0.81265</td>\n",
       "      <td>0.80704</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>6.219974e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.83667</td>\n",
       "      <td>0.73327</td>\n",
       "      <td>0.90050</td>\n",
       "      <td>0.79548</td>\n",
       "      <td>0.816480</td>\n",
       "      <td>6.089315e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.69983</td>\n",
       "      <td>0.58966</td>\n",
       "      <td>0.59403</td>\n",
       "      <td>0.65549</td>\n",
       "      <td>0.634752</td>\n",
       "      <td>4.570771e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.77724</td>\n",
       "      <td>0.69963</td>\n",
       "      <td>0.74705</td>\n",
       "      <td>0.67989</td>\n",
       "      <td>0.725952</td>\n",
       "      <td>3.837362e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.22709</td>\n",
       "      <td>0.19697</td>\n",
       "      <td>0.24752</td>\n",
       "      <td>0.29634</td>\n",
       "      <td>0.241980</td>\n",
       "      <td>3.617082e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75429</td>\n",
       "      <td>0.77023</td>\n",
       "      <td>0.84117</td>\n",
       "      <td>0.77199</td>\n",
       "      <td>0.784420</td>\n",
       "      <td>3.348224e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.83466</td>\n",
       "      <td>0.74789</td>\n",
       "      <td>0.79026</td>\n",
       "      <td>0.78343</td>\n",
       "      <td>0.789060</td>\n",
       "      <td>3.085233e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.77437</td>\n",
       "      <td>0.82925</td>\n",
       "      <td>0.84676</td>\n",
       "      <td>0.84745</td>\n",
       "      <td>0.824458</td>\n",
       "      <td>2.982357e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.83622</td>\n",
       "      <td>0.82289</td>\n",
       "      <td>0.76148</td>\n",
       "      <td>0.82535</td>\n",
       "      <td>0.811485</td>\n",
       "      <td>2.930287e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.73195</td>\n",
       "      <td>0.68290</td>\n",
       "      <td>0.66328</td>\n",
       "      <td>0.72190</td>\n",
       "      <td>0.700007</td>\n",
       "      <td>2.802312e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.69453</td>\n",
       "      <td>0.74725</td>\n",
       "      <td>0.76624</td>\n",
       "      <td>0.72330</td>\n",
       "      <td>0.732830</td>\n",
       "      <td>2.684155e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.68459</td>\n",
       "      <td>0.73805</td>\n",
       "      <td>0.69572</td>\n",
       "      <td>0.74696</td>\n",
       "      <td>0.716330</td>\n",
       "      <td>2.665593e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.79462</td>\n",
       "      <td>0.86004</td>\n",
       "      <td>0.80809</td>\n",
       "      <td>0.79665</td>\n",
       "      <td>0.814850</td>\n",
       "      <td>2.659101e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.85293</td>\n",
       "      <td>0.90603</td>\n",
       "      <td>0.90603</td>\n",
       "      <td>0.85293</td>\n",
       "      <td>0.879480</td>\n",
       "      <td>2.655000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.76751</td>\n",
       "      <td>0.72853</td>\n",
       "      <td>0.75443</td>\n",
       "      <td>0.80138</td>\n",
       "      <td>0.762962</td>\n",
       "      <td>2.624397e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95805</td>\n",
       "      <td>0.90919</td>\n",
       "      <td>0.89105</td>\n",
       "      <td>0.91218</td>\n",
       "      <td>0.917617</td>\n",
       "      <td>2.470429e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.82619</td>\n",
       "      <td>0.77258</td>\n",
       "      <td>0.79788</td>\n",
       "      <td>0.78638</td>\n",
       "      <td>0.795758</td>\n",
       "      <td>1.972166e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.88116</td>\n",
       "      <td>0.83875</td>\n",
       "      <td>0.88116</td>\n",
       "      <td>0.88341</td>\n",
       "      <td>0.871120</td>\n",
       "      <td>1.871139e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.85327</td>\n",
       "      <td>0.85327</td>\n",
       "      <td>0.85327</td>\n",
       "      <td>0.81086</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>1.836407e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.93375</td>\n",
       "      <td>0.93375</td>\n",
       "      <td>0.89221</td>\n",
       "      <td>0.93375</td>\n",
       "      <td>0.923365</td>\n",
       "      <td>1.798735e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.66328</td>\n",
       "      <td>0.66328</td>\n",
       "      <td>0.62257</td>\n",
       "      <td>0.66328</td>\n",
       "      <td>0.653102</td>\n",
       "      <td>1.762795e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.65317</td>\n",
       "      <td>0.61845</td>\n",
       "      <td>0.66388</td>\n",
       "      <td>0.65317</td>\n",
       "      <td>0.647168</td>\n",
       "      <td>1.714688e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.81879</td>\n",
       "      <td>0.85983</td>\n",
       "      <td>0.84461</td>\n",
       "      <td>0.85112</td>\n",
       "      <td>0.843587</td>\n",
       "      <td>1.530130e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.32811</td>\n",
       "      <td>0.29630</td>\n",
       "      <td>0.32943</td>\n",
       "      <td>0.32329</td>\n",
       "      <td>0.319283</td>\n",
       "      <td>1.346432e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.48860</td>\n",
       "      <td>0.45654</td>\n",
       "      <td>0.45654</td>\n",
       "      <td>0.46262</td>\n",
       "      <td>0.466075</td>\n",
       "      <td>1.323957e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.92758</td>\n",
       "      <td>0.89779</td>\n",
       "      <td>0.89779</td>\n",
       "      <td>0.905480</td>\n",
       "      <td>1.276558e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.67168</td>\n",
       "      <td>0.67050</td>\n",
       "      <td>0.67050</td>\n",
       "      <td>0.64184</td>\n",
       "      <td>0.663630</td>\n",
       "      <td>1.258968e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.86987</td>\n",
       "      <td>0.84224</td>\n",
       "      <td>0.84224</td>\n",
       "      <td>0.86344</td>\n",
       "      <td>0.854448</td>\n",
       "      <td>1.241737e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.60776</td>\n",
       "      <td>0.62468</td>\n",
       "      <td>0.63367</td>\n",
       "      <td>0.64049</td>\n",
       "      <td>0.626650</td>\n",
       "      <td>1.226315e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.88597</td>\n",
       "      <td>0.88790</td>\n",
       "      <td>0.90999</td>\n",
       "      <td>0.91017</td>\n",
       "      <td>0.898508</td>\n",
       "      <td>1.159277e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93731</td>\n",
       "      <td>0.91312</td>\n",
       "      <td>0.91312</td>\n",
       "      <td>0.93499</td>\n",
       "      <td>0.924635</td>\n",
       "      <td>1.154418e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.80338</td>\n",
       "      <td>0.81807</td>\n",
       "      <td>0.81975</td>\n",
       "      <td>0.79470</td>\n",
       "      <td>0.808975</td>\n",
       "      <td>1.041512e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.66226</td>\n",
       "      <td>0.66226</td>\n",
       "      <td>0.67444</td>\n",
       "      <td>0.64521</td>\n",
       "      <td>0.661042</td>\n",
       "      <td>1.040584e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.53544</td>\n",
       "      <td>0.51423</td>\n",
       "      <td>0.53544</td>\n",
       "      <td>0.51660</td>\n",
       "      <td>0.525427</td>\n",
       "      <td>1.004750e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.71992</td>\n",
       "      <td>0.74342</td>\n",
       "      <td>0.71962</td>\n",
       "      <td>0.73123</td>\n",
       "      <td>0.728548</td>\n",
       "      <td>9.779073e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.82493</td>\n",
       "      <td>0.81495</td>\n",
       "      <td>0.82194</td>\n",
       "      <td>0.83286</td>\n",
       "      <td>0.823670</td>\n",
       "      <td>6.424076e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.36918</td>\n",
       "      <td>0.38419</td>\n",
       "      <td>0.38020</td>\n",
       "      <td>0.38020</td>\n",
       "      <td>0.378443</td>\n",
       "      <td>5.590288e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.86517</td>\n",
       "      <td>0.86517</td>\n",
       "      <td>0.86926</td>\n",
       "      <td>0.87766</td>\n",
       "      <td>0.869315</td>\n",
       "      <td>5.099120e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.22476</td>\n",
       "      <td>0.21820</td>\n",
       "      <td>0.21820</td>\n",
       "      <td>0.22980</td>\n",
       "      <td>0.222740</td>\n",
       "      <td>4.877171e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.82908</td>\n",
       "      <td>0.82796</td>\n",
       "      <td>0.83898</td>\n",
       "      <td>0.83042</td>\n",
       "      <td>0.831610</td>\n",
       "      <td>4.343282e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70077</td>\n",
       "      <td>0.70077</td>\n",
       "      <td>0.69366</td>\n",
       "      <td>0.69113</td>\n",
       "      <td>0.696583</td>\n",
       "      <td>4.281970e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94481</td>\n",
       "      <td>0.95109</td>\n",
       "      <td>0.95109</td>\n",
       "      <td>0.94481</td>\n",
       "      <td>0.947950</td>\n",
       "      <td>3.140000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.73123</td>\n",
       "      <td>0.73123</td>\n",
       "      <td>0.73644</td>\n",
       "      <td>0.73356</td>\n",
       "      <td>0.733115</td>\n",
       "      <td>2.142434e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.83283</td>\n",
       "      <td>0.83283</td>\n",
       "      <td>0.83637</td>\n",
       "      <td>0.83283</td>\n",
       "      <td>0.833715</td>\n",
       "      <td>1.532865e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.22009</td>\n",
       "      <td>0.22009</td>\n",
       "      <td>0.22009</td>\n",
       "      <td>0.22009</td>\n",
       "      <td>0.220090</td>\n",
       "      <td>3.103168e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.06656</td>\n",
       "      <td>0.06656</td>\n",
       "      <td>0.06656</td>\n",
       "      <td>0.06656</td>\n",
       "      <td>0.066560</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29301</td>\n",
       "      <td>0.29301</td>\n",
       "      <td>0.29301</td>\n",
       "      <td>0.29301</td>\n",
       "      <td>0.293010</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.25677</td>\n",
       "      <td>0.25677</td>\n",
       "      <td>0.25677</td>\n",
       "      <td>0.25677</td>\n",
       "      <td>0.256770</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.74660</td>\n",
       "      <td>0.74660</td>\n",
       "      <td>0.74660</td>\n",
       "      <td>0.74660</td>\n",
       "      <td>0.746600</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.75201</td>\n",
       "      <td>0.75201</td>\n",
       "      <td>0.75201</td>\n",
       "      <td>0.75201</td>\n",
       "      <td>0.752010</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      view0    view1    view2    view3      mean           std\n",
       "51  0.75451  0.86365  0.68322  0.74486  0.761560  6.497714e-02\n",
       "40  0.67139  0.70392  0.81265  0.80704  0.748750  6.219974e-02\n",
       "14  0.83667  0.73327  0.90050  0.79548  0.816480  6.089315e-02\n",
       "3   0.69983  0.58966  0.59403  0.65549  0.634752  4.570771e-02\n",
       "11  0.77724  0.69963  0.74705  0.67989  0.725952  3.837362e-02\n",
       "52  0.22709  0.19697  0.24752  0.29634  0.241980  3.617082e-02\n",
       "1   0.75429  0.77023  0.84117  0.77199  0.784420  3.348224e-02\n",
       "15  0.83466  0.74789  0.79026  0.78343  0.789060  3.085233e-02\n",
       "31  0.77437  0.82925  0.84676  0.84745  0.824458  2.982357e-02\n",
       "37  0.83622  0.82289  0.76148  0.82535  0.811485  2.930287e-02\n",
       "47  0.73195  0.68290  0.66328  0.72190  0.700007  2.802312e-02\n",
       "44  0.69453  0.74725  0.76624  0.72330  0.732830  2.684155e-02\n",
       "36  0.68459  0.73805  0.69572  0.74696  0.716330  2.665593e-02\n",
       "9   0.79462  0.86004  0.80809  0.79665  0.814850  2.659101e-02\n",
       "32  0.85293  0.90603  0.90603  0.85293  0.879480  2.655000e-02\n",
       "34  0.76751  0.72853  0.75443  0.80138  0.762962  2.624397e-02\n",
       "21  0.95805  0.90919  0.89105  0.91218  0.917617  2.470429e-02\n",
       "27  0.82619  0.77258  0.79788  0.78638  0.795758  1.972166e-02\n",
       "17  0.88116  0.83875  0.88116  0.88341  0.871120  1.871139e-02\n",
       "45  0.85327  0.85327  0.85327  0.81086  0.842667  1.836407e-02\n",
       "42  0.93375  0.93375  0.89221  0.93375  0.923365  1.798735e-02\n",
       "35  0.66328  0.66328  0.62257  0.66328  0.653102  1.762795e-02\n",
       "22  0.65317  0.61845  0.66388  0.65317  0.647168  1.714688e-02\n",
       "48  0.81879  0.85983  0.84461  0.85112  0.843587  1.530130e-02\n",
       "25  0.32811  0.29630  0.32943  0.32329  0.319283  1.346432e-02\n",
       "23  0.48860  0.45654  0.45654  0.46262  0.466075  1.323957e-02\n",
       "12  0.89876  0.92758  0.89779  0.89779  0.905480  1.276558e-02\n",
       "20  0.67168  0.67050  0.67050  0.64184  0.663630  1.258968e-02\n",
       "6   0.86987  0.84224  0.84224  0.86344  0.854448  1.241737e-02\n",
       "46  0.60776  0.62468  0.63367  0.64049  0.626650  1.226315e-02\n",
       "8   0.88597  0.88790  0.90999  0.91017  0.898508  1.159277e-02\n",
       "10  0.93731  0.91312  0.91312  0.93499  0.924635  1.154418e-02\n",
       "24  0.80338  0.81807  0.81975  0.79470  0.808975  1.041512e-02\n",
       "7   0.66226  0.66226  0.67444  0.64521  0.661042  1.040584e-02\n",
       "0   0.53544  0.51423  0.53544  0.51660  0.525427  1.004750e-02\n",
       "5   0.71992  0.74342  0.71962  0.73123  0.728548  9.779073e-03\n",
       "26  0.82493  0.81495  0.82194  0.83286  0.823670  6.424076e-03\n",
       "38  0.36918  0.38419  0.38020  0.38020  0.378443  5.590288e-03\n",
       "18  0.86517  0.86517  0.86926  0.87766  0.869315  5.099120e-03\n",
       "43  0.22476  0.21820  0.21820  0.22980  0.222740  4.877171e-03\n",
       "30  0.82908  0.82796  0.83898  0.83042  0.831610  4.343282e-03\n",
       "2   0.70077  0.70077  0.69366  0.69113  0.696583  4.281970e-03\n",
       "16  0.94481  0.95109  0.95109  0.94481  0.947950  3.140000e-03\n",
       "49  0.73123  0.73123  0.73644  0.73356  0.733115  2.142434e-03\n",
       "33  0.83283  0.83283  0.83637  0.83283  0.833715  1.532865e-03\n",
       "53  0.22009  0.22009  0.22009  0.22009  0.220090  3.103168e-17\n",
       "19  1.00000  1.00000  1.00000  1.00000  1.000000  0.000000e+00\n",
       "13  0.06656  0.06656  0.06656  0.06656  0.066560  0.000000e+00\n",
       "4   0.29301  0.29301  0.29301  0.29301  0.293010  0.000000e+00\n",
       "29  1.00000  1.00000  1.00000  1.00000  1.000000  0.000000e+00\n",
       "28  0.25677  0.25677  0.25677  0.25677  0.256770  0.000000e+00\n",
       "41  1.00000  1.00000  1.00000  1.00000  1.000000  0.000000e+00\n",
       "39  0.74660  0.74660  0.74660  0.74660  0.746600  0.000000e+00\n",
       "50  0.75201  0.75201  0.75201  0.75201  0.752010  0.000000e+00"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soft by std\n",
    "ndcgs_df = ndcgs_df_dl20[3].sort_values('std', ascending=False)\n",
    "ndcgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcgs_df = ndcgs_df.sort_index()\n",
    "ndcgs_df\n",
    "# Store the result\n",
    "\n",
    "ndcgs_df.to_csv(f'./outputs/ndcgs_dl20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view0    25\n",
      "view2    11\n",
      "view3    10\n",
      "view1     8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시: ndcgs_df라는 이름의 DataFrame이 있고, 그 안에\n",
    "# 'view0', 'view1', 'view2', 'view3' 열이 존재한다고 가정합니다.\n",
    "\n",
    "# 각 행에서 최대값을 가지는 열 이름을 찾은 뒤, 그 빈도를 집계\n",
    "max_counts = ndcgs_df[['view0', 'view1', 'view2', 'view3']] \\\n",
    "    .idxmax(axis=1) \\\n",
    "    .value_counts()\n",
    "\n",
    "print(max_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(firststage_result_key='bm25_results', docid_key='docid', pid_key='pid', qrels_key='qrels', score_key='bm25_score', question_text_key='q_text', text_key='text', title_key='title', pooling_type='rv', n_special_tokens=4, store_result=False, softmax_temp=1.0, device='cuda:4', model_path='/home/tako/kjun/checkpoints/temp/0.5_0.0/tfmr_7_step2496', topk=100, score_mode='default', max_input_length=-1, padding='max_length', listwise_k=5, rerank_topk=10, decoding_strategy='single', target_seq='token', encoder_batch_size=100, seed=0, input_path='./eval_data/baseline/dl20.jsonl', output_path='./outputs/listt5-dl20_default.jsonl', special_loc=0, initial='origin', measure_flops=False, skip_no_candidate=False, skip_issubset=False, max_gen_length=101)\n",
      "Input path: ./eval_data/baseline/dl20.jsonl\n",
      "Loading model..\n",
      "Loading fid model from /home/tako/kjun/checkpoints/listt5/test/ortho_weight/10000\n",
      "Pooling type: rv\n",
      "Done! took 3.4574882984161377 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:21<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "arguments = ['--input_path', './eval_data/baseline/dl20.jsonl',\n",
    "             '--output_path', './outputs/listt5-dl20_default.jsonl',\n",
    "             '--topk', '100',\n",
    "             '--pooling_type', 'rv',\n",
    "             '--n_special_tokens', '4',\n",
    "             '--model_path', '/home/tako/kjun/checkpoints/temp/0.5_0.0/tfmr_7_step2496']\n",
    "args = parse_arg(arguments)\n",
    "args.max_gen_length = args.topk + 1\n",
    "print(args)\n",
    "\n",
    "model_path = ['/home/tako/kjun/checkpoints/listt5/test/ortho_weight/10000']\n",
    "\n",
    "ranking_score_all = []\n",
    "lhs_all = []\n",
    "psg_emb_all = []\n",
    "\n",
    "for path in model_path:\n",
    "    args.model_path = path\n",
    "    module = ListT5Evaluator(args)\n",
    "    for name in BEIR_LENGTH_MAPPING:\n",
    "        if name in module.args.input_path:\n",
    "            module.args.max_input_length = BEIR_LENGTH_MAPPING[name]\n",
    "\n",
    "    torch.cuda.empty_cache()    \n",
    "\n",
    "    ranking_score = []\n",
    "    lhs = []\n",
    "    psg_emb = []\n",
    "    for instance in tqdm(module.test_file):\n",
    "        question = instance[module.args.question_text_key]\n",
    "        items = instance[module.args.firststage_result_key][:module.args.topk]\n",
    "        topk_ctxs = [x[module.args.text_key] for x in items]\n",
    "        qrels = instance[module.args.qrels_key]\n",
    "        \n",
    "        module.model.n_passages = len(topk_ctxs)\n",
    "        module.model.encoder.encoder_batch_size = module.args.encoder_batch_size\n",
    "        # len_question.append(len(question))\n",
    "        \n",
    "        full_input_texts = module.make_listwise_text(question, topk_ctxs)\n",
    "        input_tensors = module.make_input_tensors(full_input_texts)\n",
    "        outputs = module.model.forward(input_ids=input_tensors['input_ids'], attention_mask=input_tensors['attention_mask'],)\n",
    "        ranking_score.append(outputs.ranking.cpu())\n",
    "        lhs.append(outputs.last_hidden_state.cpu())\n",
    "        psg_emb.append(outputs.passage_embed.cpu())\n",
    "    \n",
    "    ranking_score_all.append(torch.stack(ranking_score, dim=0))\n",
    "    lhs_all.append(torch.stack(lhs, dim=0))\n",
    "    psg_emb_all.append(torch.stack(psg_emb, dim=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54, 4, 1, 100])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_score = ranking_score_all[0]\n",
    "ranking_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 4, 100)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_result = ranking_score.squeeze(2).cpu().numpy()\n",
    "store_result.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "\n",
    "with open('./outputs/ranking_score.pkl', 'wb') as f:\n",
    "    pickle.dump(store_result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_values, top10_indices = torch.topk(ranking_score, k=10, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54, 4, 1, 100])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max scaling\n",
    "min_val = ranking_score.min(dim=-1, keepdim=True).values\n",
    "max_val = ranking_score.max(dim=-1, keepdim=True).values\n",
    "\n",
    "ranking_score_minmax = (ranking_score - min_val) / (max_val - min_val + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.max(\n",
       " values=tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " indices=tensor([[44],\n",
       "         [44],\n",
       "         [44],\n",
       "         [44]])),\n",
       " torch.return_types.min(\n",
       " values=tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       " indices=tensor([[98],\n",
       "         [98],\n",
       "         [93],\n",
       "         [85]])))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_score_minmax[0].max(dim=-1), ranking_score_minmax[0].min(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t2\t1\n",
      "1\t2\t1\n",
      "2\t0\t1\n",
      "3\t3\t1\n",
      "4\t2\t1\n",
      "5\t2\t1\n",
      "6\t2\t1\n",
      "7\t2\t1\n",
      "8\t2\t1\n",
      "9\t2\t1\n",
      "10\t2\t1\n",
      "11\t2\t1\n",
      "12\t2\t1\n",
      "13\t2\t1\n",
      "14\t2\t1\n",
      "15\t2\t1\n",
      "16\t2\t1\n",
      "17\t2\t1\n",
      "18\t2\t1\n",
      "19\t2\t1\n",
      "20\t2\t1\n",
      "21\t2\t1\n",
      "22\t2\t1\n",
      "23\t2\t1\n",
      "24\t2\t1\n",
      "25\t2\t1\n",
      "26\t2\t1\n",
      "27\t2\t1\n",
      "28\t2\t1\n",
      "29\t0\t1\n",
      "30\t2\t1\n",
      "31\t2\t1\n",
      "32\t2\t1\n",
      "33\t2\t1\n",
      "34\t2\t1\n",
      "35\t2\t1\n",
      "36\t2\t1\n",
      "37\t2\t1\n",
      "38\t2\t1\n",
      "39\t2\t1\n",
      "40\t2\t1\n",
      "41\t2\t1\n",
      "42\t2\t1\n",
      "43\t2\t1\n",
      "44\t2\t1\n",
      "45\t2\t1\n",
      "46\t2\t1\n",
      "47\t3\t1\n",
      "48\t2\t1\n",
      "49\t2\t1\n",
      "50\t2\t1\n",
      "51\t2\t1\n",
      "52\t2\t1\n",
      "53\t2\t1\n"
     ]
    }
   ],
   "source": [
    "topk_indices, topk_values = torch.topk(ranking_score_minmax, k=10, dim=-1)\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "query_max = []\n",
    "query_min = []\n",
    "\n",
    "for i in range(topk_values.size(0)):\n",
    "    prob = F.softmax(top10_values[i], dim=-1)  # shape = [4, 10]\n",
    "    entropy = -torch.sum(prob * torch.log2(prob), dim=-1)  # shape = [4]\n",
    "    max_idx = torch.argmax(entropy)\n",
    "    min_idx = torch.argmin(entropy)\n",
    "    print(f\"{i}\\t{max_idx}\\t{min_idx}\")\n",
    "    query_max.append(max_idx)\n",
    "    query_min.append(min_idx)\n",
    "\n",
    "# print(\"각 샘플별 Entropy:\", entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수 vs nDCG Pearson 상관계수: 0.3909180881856023\n",
      "평균 점수 vs nDCG Spearman 상관계수: 0.4226057714323844\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# (1) ndcgs_dl20.csv 불러오기\n",
    "df_ndcg_tmp = pd.read_csv('outputs/ndcgs_dl20.csv', header=0, usecols=[0, 1, 2, 3])  \n",
    "#  -> csv의 구조에 따라 header가 있는 경우 header=0으로 변경\n",
    "#  -> df_ndcg.shape가 (54, 4)라 가정\n",
    "\n",
    "# (2) ranking_score.pkl 불러오기\n",
    "with open('outputs/ranking_score.pkl', 'rb') as f:\n",
    "    ranking_score_tmp = pickle.load(f)  # shape = (54, 4, 100)이라 가정\n",
    "\n",
    "# (3) ranking_score의 요약 스칼라 만들기 (예: 평균)\n",
    "#     결과적으로 shape = (54, 4)가 됨\n",
    "mean_scores_tmp = ranking_score_tmp.mean(axis=2)   # axis=2 => 문서 차원을 평균\n",
    "# mean_scores[q, v] => q번째 Query, v번째 View의 \"평균 점수\"\n",
    "\n",
    "# (4) 2차원 데이터를 1차원으로 reshape\n",
    "#     ndcg_values와 mean_values 모두 (54*4,) 형태가 됨\n",
    "ndcg_values_tmp = df_ndcg_tmp.values.reshape(-1)        # shape=(216,)\n",
    "mean_values_tmp = mean_scores_tmp.reshape(-1)           # shape=(216,)\n",
    "\n",
    "# (5) 상관계수 계산 (피어슨, 스피어먼)\n",
    "pearson_corr = np.corrcoef(mean_values_tmp, ndcg_values_tmp)[0, 1]\n",
    "\n",
    "# 스피어먼 상관은 scipy.stats.spearmanr 등을 사용할 수 있음\n",
    "# !pip install scipy\n",
    "from scipy.stats import spearmanr\n",
    "spearman_corr, _ = spearmanr(mean_values_tmp, ndcg_values_tmp)\n",
    "\n",
    "print(\"평균 점수 vs nDCG Pearson 상관계수:\", pearson_corr)\n",
    "print(\"평균 점수 vs nDCG Spearman 상관계수:\", spearman_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 4)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ndcg_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_array shape: (54, 4)\n",
      "ranking_score shape: (54, 4, 100)\n",
      "[Top-K Sum] Pearson 상관계수: 0.48608485138684937\n",
      "[Top-K Sum] Spearman 상관계수: 0.5076618833006824\n",
      "[Top-K Mean] Pearson 상관계수: 0.48608485128822115\n",
      "[Top-K Mean] Spearman 상관계수: 0.5076618833006824\n",
      "[Top-K Max] Pearson 상관계수: 0.18103478577259868\n",
      "[Top-K Max] Spearman 상관계수: 0.22675615726941933\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# (1) ndcgs_dl20.csv 불러오기 (형태: (54, 4) 가정)\n",
    "df_ndcg_tmp = pd.read_csv('outputs/ndcgs_dl20.csv', header=0, usecols=[0, 1, 2, 3])  \n",
    "# 불필요한 mean/std 열이 있다면 drop or usecols 등으로 (54, 4)만 남기기\n",
    "# 예: df_ndcgs = df_ndcgs.drop(columns=[\"mean\",\"std\"])  # 열 이름이 mean, std인 경우\n",
    "ndcg_array = df_ndcg_tmp.values  # shape (54, 4)\n",
    "\n",
    "# (2) ranking_score.pkl 불러오기 (shape: (54, 4, 100))\n",
    "import pickle\n",
    "with open('outputs/ranking_score.pkl', 'rb') as f:\n",
    "    ranking_score_tmp = pickle.load(f)\n",
    "\n",
    "print(\"ndcg_array shape:\", ndcg_array.shape)  # (54, 4) 확인\n",
    "print(\"ranking_score shape:\", ranking_score_tmp.shape)  # (54, 4, 100) 확인\n",
    "\n",
    "# (3) 상위 K개만 집중\n",
    "K = 10\n",
    "\n",
    "# 아래 로직: 문서 점수를 내림차순으로 정렬한 뒤 앞쪽 K개를 선택\n",
    "# np.sort(axis=-1)는 오름차순 정렬이므로, 뒤쪽 K개를 가져오거나, -x로 정렬하는 방식을 사용\n",
    "# 여기서는 오름차순 정렬 후 마지막 K개를 가져오는 예시\n",
    "\n",
    "# axis=2(마지막 축) 기준으로 오름차순 정렬\n",
    "sorted_scores = np.sort(ranking_score_tmp, axis=2)  # shape 동일 (54, 4, 100) \n",
    "# sorted_scores[q, v, :]는 해당 (q,v)의 모든 문서를 낮은 점수->높은 점수 순으로 정렬\n",
    "\n",
    "# 마지막 K개(가장 높은 K개) 추출\n",
    "topk_scores = sorted_scores[:, :, -K:]  # shape=(54,4,K)\n",
    "\n",
    "# (4) topK 점수 요약(예: 합, 평균, 최댓값 등)\n",
    "topk_sum = topk_scores.sum(axis=2)     # shape=(54,4)  (K개 합)\n",
    "topk_mean = topk_scores.mean(axis=2)   # shape=(54,4)  (K개 평균)\n",
    "topk_max = topk_scores.max(axis=2)     # shape=(54,4)  (K개 중 최댓값)\n",
    "\n",
    "# 필요에 따라 한 가지만 사용할 수도 있고, 여러 개를 비교해 볼 수도 있음.\n",
    "# 여기서는 topk_sum를 예시로 들어서 nDCG와 상관관계 계산\n",
    "\n",
    "sum_values = topk_sum.reshape(-1)        # (54*4=216,)\n",
    "ndcg_values = ndcg_array.reshape(-1)     # (216,)\n",
    "\n",
    "# (5) 상관계수 계산\n",
    "pearson_corr = np.corrcoef(sum_values, ndcg_values)[0, 1]\n",
    "spearman_corr, _ = spearmanr(sum_values, ndcg_values)\n",
    "\n",
    "print(\"[Top-K Sum] Pearson 상관계수:\", pearson_corr)\n",
    "print(\"[Top-K Sum] Spearman 상관계수:\", spearman_corr)\n",
    "\n",
    "# (6) 필요하면 mean, max도 똑같이 해볼 수 있음\n",
    "mean_values = topk_mean.reshape(-1)\n",
    "max_values = topk_max.reshape(-1)\n",
    "\n",
    "pearson_corr_mean = np.corrcoef(mean_values, ndcg_values)[0, 1]\n",
    "spearman_corr_mean, _ = spearmanr(mean_values, ndcg_values)\n",
    "\n",
    "print(\"[Top-K Mean] Pearson 상관계수:\", pearson_corr_mean)\n",
    "print(\"[Top-K Mean] Spearman 상관계수:\", spearman_corr_mean)\n",
    "\n",
    "pearson_corr_max = np.corrcoef(max_values, ndcg_values)[0, 1]\n",
    "spearman_corr_max, _ = spearmanr(max_values, ndcg_values)\n",
    "\n",
    "print(\"[Top-K Max] Pearson 상관계수:\", pearson_corr_max)\n",
    "print(\"[Top-K Max] Spearman 상관계수:\", spearman_corr_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_array shape: (54, 4)\n",
      "ranking_score shape: (54, 4, 100)\n",
      "[Top-K Sum 기반 View 선택] 평균 nDCG: 0.7062\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# (1) nDCG 정보 불러오기 (CSV)\n",
    "df_ndcg_tmp = pd.read_csv('outputs/ndcgs_dl20.csv', header=0, usecols=[0, 1, 2, 3])  \n",
    "# 만약 mean/std 열이 있으면 drop 등으로 (54,4)만 남기세요.\n",
    "# 예: df_ndcgs = df_ndcgs.drop(columns=['mean','std'])  # 열 이름이 mean, std 인 경우\n",
    "ndcg_array = df_ndcg_tmp.values  # shape (54, 4) 가정\n",
    "\n",
    "# (2) 문서 점수(ranking_score) 불러오기\n",
    "with open('outputs/ranking_score.pkl', 'rb') as f:\n",
    "    ranking_score_temp = pickle.load(f)  # shape (54, 4, 100)\n",
    "\n",
    "print(\"ndcg_array shape:\", ndcg_array.shape)        # (54, 4)\n",
    "print(\"ranking_score shape:\", ranking_score_temp.shape)  # (54, 4, 100)\n",
    "\n",
    "# (3) 상위 K개 설정\n",
    "K = 10\n",
    "\n",
    "# 오름차순 정렬 후 마지막 K개가 \"가장 높은 점수 K개\"\n",
    "sorted_scores = np.sort(ranking_score_temp, axis=2)   # shape (54,4,100)\n",
    "topk_scores = sorted_scores[:, :, -K:]           # shape (54,4,K)\n",
    "\n",
    "# (4) 상위 K개 점수 합\n",
    "topk_sum = topk_scores.sum(axis=2)  # shape (54,4)\n",
    "\n",
    "# (5) Query별로 \"Top-K 합이 가장 큰 View\"를 선택\n",
    "best_view_pred = topk_sum.argmax(axis=1)  # shape (54,)\n",
    "\n",
    "# (6) 선택한 View의 nDCG를 모아서 평균\n",
    "selected_ndcgs = []\n",
    "for q in range(topk_sum.shape[0]):  # 54개 Query\n",
    "    v_pred = best_view_pred[q]\n",
    "    selected_ndcgs.append(ndcg_array[q, v_pred])\n",
    "\n",
    "mean_ndcg = np.mean(selected_ndcgs)\n",
    "print(f\"[Top-K Sum 기반 View 선택] 평균 nDCG: {mean_ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([54, 4, 1, 768]), torch.Size([54, 4, 100, 768]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs_all[0].shape, psg_emb_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.7543],\n",
      "        [20.2297],\n",
      "        [14.9376],\n",
      "        [11.3495]])\n",
      "tensor([2.0990, 2.2739, 1.9247, 2.0057])\n"
     ]
    }
   ],
   "source": [
    "test = lhs_all[0][0]\n",
    "print(test.norm(dim=-1))\n",
    "print(psg_emb_all[0][0].norm(dim=-1).mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 - Max Index: tensor([[44],\n",
      "        [44],\n",
      "        [44],\n",
      "        [44]])\n",
      "Query 2 - Max Index: tensor([[25],\n",
      "        [25],\n",
      "        [25],\n",
      "        [25]])\n",
      "Query 3 - Max Index: tensor([[11],\n",
      "        [11],\n",
      "        [55],\n",
      "        [55]])\n",
      "Query 4 - Max Index: tensor([[5],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 5 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 6 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 7 - Max Index: tensor([[24],\n",
      "        [24],\n",
      "        [24],\n",
      "        [24]])\n",
      "Query 8 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 9 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 10 - Max Index: tensor([[2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2]])\n",
      "Query 11 - Max Index: tensor([[10],\n",
      "        [10],\n",
      "        [10],\n",
      "        [10]])\n",
      "Query 12 - Max Index: tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "Query 13 - Max Index: tensor([[1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [1]])\n",
      "Query 14 - Max Index: tensor([[40],\n",
      "        [40],\n",
      "        [40],\n",
      "        [40]])\n",
      "Query 15 - Max Index: tensor([[35],\n",
      "        [35],\n",
      "        [ 3],\n",
      "        [ 3]])\n",
      "Query 16 - Max Index: tensor([[68],\n",
      "        [68],\n",
      "        [68],\n",
      "        [68]])\n",
      "Query 17 - Max Index: tensor([[ 4],\n",
      "        [14],\n",
      "        [ 4],\n",
      "        [ 4]])\n",
      "Query 18 - Max Index: tensor([[7],\n",
      "        [9],\n",
      "        [7],\n",
      "        [7]])\n",
      "Query 19 - Max Index: tensor([[7],\n",
      "        [7],\n",
      "        [7],\n",
      "        [7]])\n",
      "Query 20 - Max Index: tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1]])\n",
      "Query 21 - Max Index: tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "Query 22 - Max Index: tensor([[7],\n",
      "        [8],\n",
      "        [8],\n",
      "        [8]])\n",
      "Query 23 - Max Index: tensor([[87],\n",
      "        [87],\n",
      "        [89],\n",
      "        [87]])\n",
      "Query 24 - Max Index: tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 25 - Max Index: tensor([[34],\n",
      "        [34],\n",
      "        [34],\n",
      "        [34]])\n",
      "Query 26 - Max Index: tensor([[4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4]])\n",
      "Query 27 - Max Index: tensor([[29],\n",
      "        [29],\n",
      "        [29],\n",
      "        [16]])\n",
      "Query 28 - Max Index: tensor([[6],\n",
      "        [6],\n",
      "        [6],\n",
      "        [6]])\n",
      "Query 29 - Max Index: tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "Query 30 - Max Index: tensor([[39],\n",
      "        [39],\n",
      "        [39],\n",
      "        [39]])\n",
      "Query 31 - Max Index: tensor([[5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]])\n",
      "Query 32 - Max Index: tensor([[57],\n",
      "        [57],\n",
      "        [57],\n",
      "        [57]])\n",
      "Query 33 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 34 - Max Index: tensor([[5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]])\n",
      "Query 35 - Max Index: tensor([[8],\n",
      "        [8],\n",
      "        [8],\n",
      "        [8]])\n",
      "Query 36 - Max Index: tensor([[13],\n",
      "        [13],\n",
      "        [34],\n",
      "        [13]])\n",
      "Query 37 - Max Index: tensor([[7],\n",
      "        [1],\n",
      "        [7],\n",
      "        [7]])\n",
      "Query 38 - Max Index: tensor([[13],\n",
      "        [13],\n",
      "        [ 6],\n",
      "        [13]])\n",
      "Query 39 - Max Index: tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "Query 40 - Max Index: tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "Query 41 - Max Index: tensor([[12],\n",
      "        [12],\n",
      "        [12],\n",
      "        [12]])\n",
      "Query 42 - Max Index: tensor([[62],\n",
      "        [62],\n",
      "        [ 9],\n",
      "        [62]])\n",
      "Query 43 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 44 - Max Index: tensor([[62],\n",
      "        [21],\n",
      "        [21],\n",
      "        [21]])\n",
      "Query 45 - Max Index: tensor([[3],\n",
      "        [7],\n",
      "        [7],\n",
      "        [7]])\n",
      "Query 46 - Max Index: tensor([[5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]])\n",
      "Query 47 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 48 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 49 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 50 - Max Index: tensor([[52],\n",
      "        [52],\n",
      "        [52],\n",
      "        [52]])\n",
      "Query 51 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "Query 52 - Max Index: tensor([[21],\n",
      "        [ 3],\n",
      "        [21],\n",
      "        [21]])\n",
      "Query 53 - Max Index: tensor([[57],\n",
      "        [57],\n",
      "        [57],\n",
      "        [57]])\n",
      "Query 54 - Max Index: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "view_max_indices = []\n",
    "for i in range(ranking_score_all[0].size(0)):\n",
    "    # Print MAX & MiN Indices of LOGITS\n",
    "\n",
    "    max_index = ranking_score_all[0][i].max(dim=-1).indices\n",
    "    min_index = ranking_score_all[0][i].min(dim=-1).indices\n",
    "    print(f\"Query {i+1} - Max Index: {max_index}\")\n",
    "    view_max_indices.append(max_index)\n",
    "\n",
    "    # print(f\"Query {i+1} - Max: {ranking_score_all[0][i].max()}, Min: {ranking_score_all[0][i].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "test = ranking_score_all[0].sum(dim=1)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 - Max Index: tensor([44])\n",
      "Query 2 - Max Index: tensor([25])\n",
      "Query 3 - Max Index: tensor([55])\n",
      "Query 4 - Max Index: tensor([0])\n",
      "Query 5 - Max Index: tensor([0])\n",
      "Query 6 - Max Index: tensor([0])\n",
      "Query 7 - Max Index: tensor([24])\n",
      "Query 8 - Max Index: tensor([0])\n",
      "Query 9 - Max Index: tensor([0])\n",
      "Query 10 - Max Index: tensor([2])\n",
      "Query 11 - Max Index: tensor([10])\n",
      "Query 12 - Max Index: tensor([3])\n",
      "Query 13 - Max Index: tensor([1])\n",
      "Query 14 - Max Index: tensor([40])\n",
      "Query 15 - Max Index: tensor([3])\n",
      "Query 16 - Max Index: tensor([68])\n",
      "Query 17 - Max Index: tensor([4])\n",
      "Query 18 - Max Index: tensor([7])\n",
      "Query 19 - Max Index: tensor([7])\n",
      "Query 20 - Max Index: tensor([2])\n",
      "Query 21 - Max Index: tensor([2])\n",
      "Query 22 - Max Index: tensor([8])\n",
      "Query 23 - Max Index: tensor([87])\n",
      "Query 24 - Max Index: tensor([0])\n",
      "Query 25 - Max Index: tensor([34])\n",
      "Query 26 - Max Index: tensor([4])\n",
      "Query 27 - Max Index: tensor([29])\n",
      "Query 28 - Max Index: tensor([6])\n",
      "Query 29 - Max Index: tensor([1])\n",
      "Query 30 - Max Index: tensor([39])\n",
      "Query 31 - Max Index: tensor([5])\n",
      "Query 32 - Max Index: tensor([57])\n",
      "Query 33 - Max Index: tensor([0])\n",
      "Query 34 - Max Index: tensor([5])\n",
      "Query 35 - Max Index: tensor([8])\n",
      "Query 36 - Max Index: tensor([13])\n",
      "Query 37 - Max Index: tensor([7])\n",
      "Query 38 - Max Index: tensor([13])\n",
      "Query 39 - Max Index: tensor([1])\n",
      "Query 40 - Max Index: tensor([1])\n",
      "Query 41 - Max Index: tensor([12])\n",
      "Query 42 - Max Index: tensor([62])\n",
      "Query 43 - Max Index: tensor([0])\n",
      "Query 44 - Max Index: tensor([21])\n",
      "Query 45 - Max Index: tensor([7])\n",
      "Query 46 - Max Index: tensor([5])\n",
      "Query 47 - Max Index: tensor([0])\n",
      "Query 48 - Max Index: tensor([0])\n",
      "Query 49 - Max Index: tensor([0])\n",
      "Query 50 - Max Index: tensor([52])\n",
      "Query 51 - Max Index: tensor([0])\n",
      "Query 52 - Max Index: tensor([21])\n",
      "Query 53 - Max Index: tensor([57])\n",
      "Query 54 - Max Index: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for i in range(test.size(0)):\n",
    "    # Print MAX & MiN Indices of LOGITS\n",
    "    max_index = test[i].max(dim=-1).indices\n",
    "    # min_index = test[i].min(dim=-1).indices\n",
    "    print(f\"Query {i+1} - Max Index: {max_index}\")\n",
    "    view_max_indices.append(max_index)\n",
    "    # print(f\"Query {i+1} - Max: {ranking_score_all[0][i].max()}, Min: {ranking_score_all[0][i].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_max_indices_tensor = torch.stack(view_max_indices[:54], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_max_indices_tensor = torch.stack(view_max_indices[54:], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([54, 4, 1]), torch.Size([54, 1]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_max_indices_tensor.shape, sum_max_indices_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    View1  View2  View3  View4  SUM\n",
      "0      44     44     44     44   44\n",
      "1      25     25     25     25   25\n",
      "2      11     11     55     55   55\n",
      "3       5      0      0      0    0\n",
      "4       0      0      0      0    0\n",
      "5       0      0      0      0    0\n",
      "6      24     24     24     24   24\n",
      "7       0      0      0      0    0\n",
      "8       0      0      0      0    0\n",
      "9       2      3      2      2    2\n",
      "10     10     10     10     10   10\n",
      "11      3      3      3      3    3\n",
      "12      1      3      1      1    1\n",
      "13     40     40     40     40   40\n",
      "14     35     35      3      3    3\n",
      "15     68     68     68     68   68\n",
      "16      4     14      4      4    4\n",
      "17      7      9      7      7    7\n",
      "18      7      7      7      7    7\n",
      "19      2      2      2      1    2\n",
      "20      2      2      2      2    2\n",
      "21      7      8      8      8    8\n",
      "22     87     87     89     87   87\n",
      "23      1      0      0      0    0\n",
      "24     34     34     34     34   34\n",
      "25      4      4      4      4    4\n",
      "26     29     29     29     16   29\n",
      "27      6      6      6      6    6\n",
      "28      1      1      1      1    1\n",
      "29     39     39     39     39   39\n",
      "30      5      5      5      5    5\n",
      "31     57     57     57     57   57\n",
      "32      0      0      0      0    0\n",
      "33      5      5      5      5    5\n",
      "34      8      8      8      8    8\n",
      "35     13     13     34     13   13\n",
      "36      7      1      7      7    7\n",
      "37     13     13      6     13   13\n",
      "38      1      1      1      1    1\n",
      "39      1      1      1      1    1\n",
      "40     12     12     12     12   12\n",
      "41     62     62      9     62   62\n",
      "42      0      0      0      0    0\n",
      "43     62     21     21     21   21\n",
      "44      3      7      7      7    7\n",
      "45      5      5      5      5    5\n",
      "46      0      0      0      0    0\n",
      "47      0      0      0      0    0\n",
      "48      0      0      0      0    0\n",
      "49     52     52     52     52   52\n",
      "50      0      0      0      0    0\n",
      "51     21      3     21     21   21\n",
      "52     57     57     57     57   57\n",
      "53      0      0      0      0    0\n"
     ]
    }
   ],
   "source": [
    "# view_max_indices_tensor: [54, 4, 1] → squeeze to [54, 4]\n",
    "view_max = view_max_indices_tensor.squeeze(-1)  # [54, 4]\n",
    "\n",
    "# sum_max_indices_tensor: [54, 1]\n",
    "sum_max = sum_max_indices_tensor  # [54, 1]\n",
    "\n",
    "# concat along the last dimension (dim=1)\n",
    "combined = torch.cat([view_max, sum_max], dim=1)  # [54, 5]\n",
    "\n",
    "# 보기 좋게 출력하려면\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(combined.cpu().numpy(), columns=[\"View1\", \"View2\", \"View3\", \"View4\", \"SUM\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(firststage_result_key='bm25_results', docid_key='docid', pid_key='pid', qrels_key='qrels', score_key='bm25_score', question_text_key='q_text', text_key='text', title_key='title', pooling_type='rv', n_special_tokens=4, store_result=False, softmax_temp=1.0, device='cuda:4', model_path='/home/tako/kjun/checkpoints/temp/0.5_0.0/tfmr_7_step2496', topk=100, score_mode='default', max_input_length=-1, padding='max_length', listwise_k=5, rerank_topk=10, decoding_strategy='single', target_seq='token', encoder_batch_size=100, seed=0, input_path='./eval_data/baseline/dl20.jsonl', output_path='./outputs/listt5-dl20_default.jsonl', special_loc=0, initial='origin', measure_flops=False, skip_no_candidate=False, skip_issubset=False, max_gen_length=101)\n",
      "Input path: ./eval_data/baseline/dl20.jsonl\n",
      "Loading model..\n",
      "Loading fid model from /home/tako/kjun/checkpoints/temp/tfmr_0_step25000\n",
      "Pooling type: rv\n",
      "Done! took 3.4578142166137695 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:21<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "arguments = ['--input_path', './eval_data/baseline/dl20.jsonl',\n",
    "             '--output_path', './outputs/listt5-dl20_default.jsonl',\n",
    "             '--topk', '100',\n",
    "             '--pooling_type', 'rv',\n",
    "             '--n_special_tokens', '4',\n",
    "             '--model_path', '/home/tako/kjun/checkpoints/temp/0.5_0.0/tfmr_7_step2496']\n",
    "args = parse_arg(arguments)\n",
    "args.max_gen_length = args.topk + 1\n",
    "print(args)\n",
    "\n",
    "model_path = ['/home/tako/kjun/checkpoints/temp/tfmr_0_step25000']\n",
    "\n",
    "ranking_score_all_2 = []\n",
    "lhs_all_2 = []\n",
    "psg_emb_all_2 = []\n",
    "\n",
    "for path in model_path:\n",
    "    args.model_path = path\n",
    "    module = ListT5Evaluator(args)\n",
    "    for name in BEIR_LENGTH_MAPPING:\n",
    "        if name in module.args.input_path:\n",
    "            module.args.max_input_length = BEIR_LENGTH_MAPPING[name]\n",
    "\n",
    "    torch.cuda.empty_cache()    \n",
    "\n",
    "    ranking_score = []\n",
    "    lhs = []\n",
    "    psg_emb = []\n",
    "    for instance in tqdm(module.test_file):\n",
    "        question = instance[module.args.question_text_key]\n",
    "        items = instance[module.args.firststage_result_key][:module.args.topk]\n",
    "        topk_ctxs = [x[module.args.text_key] for x in items]\n",
    "        qrels = instance[module.args.qrels_key]\n",
    "        \n",
    "        module.model.n_passages = len(topk_ctxs)\n",
    "        module.model.encoder.encoder_batch_size = module.args.encoder_batch_size\n",
    "        # len_question.append(len(question))\n",
    "        \n",
    "        full_input_texts = module.make_listwise_text(question, topk_ctxs)\n",
    "        input_tensors = module.make_input_tensors(full_input_texts)\n",
    "        outputs = module.model.forward(input_ids=input_tensors['input_ids'], attention_mask=input_tensors['attention_mask'],)\n",
    "        ranking_score.append(outputs.ranking.cpu())\n",
    "        lhs.append(outputs.last_hidden_state.cpu())\n",
    "        psg_emb.append(outputs.passage_embed.cpu())\n",
    "    \n",
    "    ranking_score_all_2.append(torch.stack(ranking_score, dim=0))\n",
    "    lhs_all_2.append(torch.stack(lhs, dim=0))\n",
    "    psg_emb_all_2.append(torch.stack(psg_emb, dim=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    View1  View2  View3  View4  SUM\n",
      "0      44     13     13     13   13\n",
      "1      25     25     25     25   25\n",
      "2      35     30     55     55   55\n",
      "3       5      0      0      0    5\n",
      "4       0      0      0      0    0\n",
      "5      23      0      0     49    0\n",
      "6      24     24     24     24   24\n",
      "7       0      0      0      0    0\n",
      "8       0      0      0      0    0\n",
      "9       2      3      2      2    2\n",
      "10      2      0      0      0    0\n",
      "11      3      3     13      3    3\n",
      "12      1      2     11      6    1\n",
      "13      1     40     40     40   40\n",
      "14     35     35     37     28   35\n",
      "15     68     68     68     68   68\n",
      "16      4      4      0      4    4\n",
      "17      7      9      0      7    7\n",
      "18     15      7      7      7    7\n",
      "19      0      0      5      0    0\n",
      "20      2      4      0      2    2\n",
      "21      7      1     13     13    7\n",
      "22     30     89     30     13   30\n",
      "23      0      0      0      0    0\n",
      "24     63     34     99     63   63\n",
      "25      4      4      4      4    4\n",
      "26     29     29     29     47   29\n",
      "27      6      6      6      6    6\n",
      "28      1      6      1      1    1\n",
      "29     29     29     39     39   29\n",
      "30      5      6      5      5    5\n",
      "31     57     57     57     57   57\n",
      "32      0      0      0      0    0\n",
      "33      5      6      6      5    5\n",
      "34     13     15      4     13   13\n",
      "35     13     13     13     13   13\n",
      "36      7      1      7      1    1\n",
      "37     16     16     11     13   16\n",
      "38      1      1      1      1    1\n",
      "39      1      2      1      2    1\n",
      "40     12     16     12     12   12\n",
      "41     62     62     62     62   62\n",
      "42     10     10     10      0   10\n",
      "43     62     62     62     62   62\n",
      "44      7      7      7      7    7\n",
      "45      5      5      5      5    5\n",
      "46      0      0      0      0    0\n",
      "47      0      0      0      0    0\n",
      "48      0      0      0      0    0\n",
      "49     52     52     52     52   52\n",
      "50      0      1      0      0    0\n",
      "51      3      3      3     21    3\n",
      "52     40     31     23     21   23\n",
      "53      0      1      0      0    0\n"
     ]
    }
   ],
   "source": [
    "view_max_indices = []\n",
    "for i in range(ranking_score_all_2[0].size(0)):\n",
    "    # Print MAX & MiN Indices of LOGITS\n",
    "\n",
    "    max_index = ranking_score_all_2[0][i].max(dim=-1).indices\n",
    "    min_index = ranking_score_all_2[0][i].min(dim=-1).indices\n",
    "    # print(f\"Query {i+1} - Max Index: {max_index}\")\n",
    "    view_max_indices.append(max_index)\n",
    "\n",
    "    # print(f\"Query {i+1} - Max: {ranking_score_all_2[0][i].max()}, Min: {ranking_score_all_2[0][i].min()}\")\n",
    "\n",
    "test = ranking_score_all_2[0].sum(dim=1)\n",
    "# print(test.shape) \n",
    "for i in range(test.size(0)):\n",
    "    # Print MAX & MiN Indices of LOGITS\n",
    "    max_index = test[i].max(dim=-1).indices\n",
    "    # min_index = test[i].min(dim=-1).indices\n",
    "    # print(f\"Query {i+1} - Max Index: {max_index}\")\n",
    "    view_max_indices.append(max_index)\n",
    "    # print(f\"Query {i+1} - Max: {ranking_score_all_2[0][i].max()}, Min: {ranking_score_all[0][i].min()}\")\n",
    "\n",
    "\n",
    "view_max_indices_tensor = torch.stack(view_max_indices[:54], dim=0)\n",
    "sum_max_indices_tensor = torch.stack(view_max_indices[54:], dim=0)\n",
    "\n",
    "\n",
    "# view_max_indices_tensor: [54, 4, 1] → squeeze to [54, 4]\n",
    "view_max = view_max_indices_tensor.squeeze(-1)  # [54, 4]\n",
    "\n",
    "# sum_max_indices_tensor: [54, 1]\n",
    "sum_max = sum_max_indices_tensor  # [54, 1]\n",
    "\n",
    "# concat along the last dimension (dim=1)\n",
    "combined = torch.cat([view_max, sum_max], dim=1)  # [54, 5]\n",
    "\n",
    "# 보기 좋게 출력하려면\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(combined.cpu().numpy(), columns=[\"View1\", \"View2\", \"View3\", \"View4\", \"SUM\"])\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "listt5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
